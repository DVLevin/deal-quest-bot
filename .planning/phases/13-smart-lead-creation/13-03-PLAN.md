---
phase: 13-smart-lead-creation
plan: 03
type: execute
wave: 2
depends_on: ["13-01", "13-02"]
files_modified:
  - bot/handlers/support.py
  - data/pipelines/support_photo.yaml
autonomous: true

must_haves:
  truths:
    - "Photo inputs route through two-step extraction->strategist pipeline"
    - "URL inputs show guidance message instead of attempting scrape"
    - "Text inputs still route through existing strategist pipeline unchanged"
    - "Extracted prospect data is passed to strategist for analysis"
    - "Images are pre-resized before vision model calls"
  artifacts:
    - path: "data/pipelines/support_photo.yaml"
      provides: "Two-step photo pipeline config"
      contains: "extraction"
    - path: "bot/handlers/support.py"
      provides: "Input routing and pipeline selection"
      contains: "URL_PATTERN"
  key_links:
    - from: "bot/handlers/support.py"
      to: "data/pipelines/support_photo.yaml"
      via: "load_pipeline('support_photo')"
      pattern: "load_pipeline.*support_photo"
    - from: "bot/handlers/support.py"
      to: "bot/services/image_utils.py"
      via: "pre_resize_image import"
      pattern: "from bot.services.image_utils import pre_resize_image"
---

<objective>
Wire the two-step extraction->strategist pipeline for photo inputs and add input type routing.

Purpose: Photo inputs need to go through ExtractionAgent first to get clean OCR data, then StrategistAgent for analysis. URL inputs should show guidance to paste text instead of attempting scrape. Text inputs continue through the existing pipeline unchanged.

Output: New support_photo.yaml pipeline config, input routing in support.py, and image pre-resize integration.
</objective>

<execution_context>
@/Users/dmytrolevin/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dmytrolevin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/13-smart-lead-creation/13-RESEARCH.md
@.planning/phases/13-smart-lead-creation/13-01-SUMMARY.md
@.planning/phases/13-smart-lead-creation/13-02-SUMMARY.md

# Source files
@bot/handlers/support.py
@data/pipelines/support.yaml
@bot/pipeline/context.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create support_photo pipeline config</name>
  <files>data/pipelines/support_photo.yaml</files>
  <action>
Create new pipeline config `data/pipelines/support_photo.yaml` for the two-step photo workflow:

```yaml
name: support_photo
description: "Photo lead creation: extract OCR -> strategist analysis -> memory update"
steps:
  # Step 1: Extract structured data from screenshot (focused OCR, no KB)
  - agent: extraction
    mode: sequential
    input_mapping:
      # ExtractionAgent reads image_b64 from pipeline context
      # No knowledge_base injection - pure OCR

  # Step 2: Run strategist with extracted data as context
  - agent: strategist
    mode: sequential
    input_mapping:
      knowledge_base: "ctx.knowledge_base"
      user_memory: "ctx.user_memory"
      casebook_text: "ctx.casebook_text"
      # Extracted data will be available via ctx.get_result("extraction")

  # Step 3: Background memory update (same as regular support)
  - agent: memory
    mode: background
    input_mapping:
      strategist_output: "result.strategist"
      user_memory: "ctx.user_memory"
```

This pipeline runs extraction first, then passes results to strategist. The pipeline runner already handles result passing via `ctx.set_result()` / `ctx.get_result()`.
  </action>
  <verify>
```bash
# Check file exists and has correct structure
head -20 data/pipelines/support_photo.yaml

# Verify YAML is valid
python3 -c "import yaml; yaml.safe_load(open('data/pipelines/support_photo.yaml')); print('Valid YAML')"
```
  </verify>
  <done>support_photo.yaml pipeline config exists with extraction -> strategist -> memory steps.</done>
</task>

<task type="auto">
  <name>Task 2: Add input routing and image pre-resize to support handler</name>
  <files>bot/handlers/support.py</files>
  <action>
Modify `bot/handlers/support.py` to:

1. Add imports at top of file:
```python
import re
from bot.services.image_utils import pre_resize_image
```

2. Add URL detection pattern and guidance message after imports:
```python
# URL detection pattern for routing
URL_PATTERN = re.compile(
    r'(?:https?://)?'  # Optional protocol
    r'(?:www\.)?'      # Optional www
    r'(?:'
    r'linkedin\.com/(?:in|pub|profile)/[\w-]+'  # LinkedIn profiles
    r'|'
    r'[a-zA-Z0-9][-a-zA-Z0-9]*\.[a-zA-Z]{2,}'   # Generic domains
    r')'
)

URL_GUIDANCE_MESSAGE = (
    "I noticed you sent a URL. Unfortunately, I can't automatically "
    "scrape web pages (LinkedIn blocks this anyway).\n\n"
    "Instead, please:\n"
    "1. Open the profile in your browser\n"
    "2. Select and copy the visible text\n"
    "3. Paste it here\n\n"
    "Or take a screenshot and send it as a photo!"
)
```

3. Modify `on_support_input` (text handler, around line 760) to detect URLs:
```python
@router.message(SupportState.waiting_input)
async def on_support_input(
    message: Message,
    state: FSMContext,
    # ... existing params ...
) -> None:
    """Process text input through strategist pipeline."""
    tg_id = message.from_user.id  # type: ignore[union-attr]
    user_input = message.text or ""

    # Check for URL input and show guidance
    if URL_PATTERN.search(user_input.strip()):
        await message.answer(URL_GUIDANCE_MESSAGE)
        return  # Stay in waiting_input state so user can paste text

    result = validate_user_input(user_input, context="support", min_length=10)
    # ... rest of existing handler ...
```

4. Modify `on_support_photo` (photo handler, around line 617) to:
   a. Pre-resize the image before base64 encoding
   b. Use the support_photo pipeline instead of support pipeline

Find the section after downloading the photo (around line 644-663) and modify:
```python
# Download the largest photo from Telegram
photo = message.photo[-1]  # type: ignore[index]
file = await bot.get_file(photo.file_id)

file_bytes_io = io.BytesIO()
await bot.download_file(file.file_path, file_bytes_io)  # type: ignore[arg-type]
file_bytes = file_bytes_io.getvalue()

# Pre-resize image for vision models (max 1568px)
file_bytes = pre_resize_image(file_bytes)
```

5. Modify `_run_support_pipeline` to accept a `pipeline_name` parameter and use it:

Add parameter to function signature (around line 102):
```python
async def _run_support_pipeline(
    *,
    user_input: str,
    tg_id: int,
    # ... existing params ...
    pipeline_name: str = "support",  # NEW: default to regular support
) -> None:
```

Then use it where pipeline is loaded (around line 161):
```python
# Run support pipeline (or support_photo for images)
pipeline_config = load_pipeline(pipeline_name)
```

6. Update the `on_support_photo` call to `_run_support_pipeline` to pass the pipeline name:
```python
await _run_support_pipeline(
    user_input=user_input,
    # ... existing params ...
    pipeline_name="support_photo",  # Use two-step pipeline for photos
)
```

7. Modify StrategistAgent input to include extracted data when available. In `_run_support_pipeline`, after the pipeline runs, check for extraction results and include them in prospect_info handling:

After `strategist_result = ctx.get_result("strategist")` (around line 168), add:
```python
# If extraction ran, merge its data into prospect_info
extraction_result = ctx.get_result("extraction")
if extraction_result and extraction_result.success:
    extracted = extraction_result.data or {}
    # Extraction data provides cleaner names than strategist parsing
    if "prospect_info" not in output_data:
        output_data["prospect_info"] = {}
    # Only override if extraction found values
    for field in ("first_name", "last_name", "title", "company", "geography"):
        if extracted.get(field) and not output_data["prospect_info"].get(field):
            output_data["prospect_info"][field] = extracted[field]
    # Add context as additional signal
    if extracted.get("context"):
        output_data["prospect_info"]["extracted_context"] = extracted["context"]
```
  </action>
  <verify>
```bash
# Check URL pattern exists
grep "URL_PATTERN" bot/handlers/support.py

# Check pre_resize_image import
grep "from bot.services.image_utils import pre_resize_image" bot/handlers/support.py

# Check pipeline_name parameter added
grep "pipeline_name.*support" bot/handlers/support.py

# Check support_photo pipeline is used for photos
grep "support_photo" bot/handlers/support.py

# Verify module still imports
python3 -c "import bot.handlers.support; print('OK')"
```
  </verify>
  <done>
- URL inputs show guidance message instead of attempting pipeline
- Photo inputs use support_photo pipeline with two-step extraction
- Images are pre-resized before vision model calls
- Extraction results are merged into prospect_info for lead creation
- Text inputs continue through regular support pipeline unchanged
  </done>
</task>

</tasks>

<verification>
1. Pipeline config valid:
   ```bash
   python3 -c "from bot.pipeline.config_loader import load_pipeline; p = load_pipeline('support_photo'); print(f'Steps: {len(p.steps)}')"
   ```

2. URL routing works:
   ```bash
   grep -A2 "URL_PATTERN.search" bot/handlers/support.py
   ```

3. Photo handler uses support_photo pipeline:
   ```bash
   grep "support_photo" bot/handlers/support.py
   ```

4. Pre-resize integrated:
   ```bash
   grep "pre_resize_image" bot/handlers/support.py
   ```
</verification>

<success_criteria>
- data/pipelines/support_photo.yaml exists with extraction -> strategist -> memory steps
- URL inputs receive guidance message and stay in waiting_input state
- Photo inputs route through support_photo pipeline
- Images are pre-resized to 1568px max before encoding
- Extraction results are merged into output_data["prospect_info"]
- Text inputs continue through regular support pipeline with no changes
- No regressions in existing functionality
</success_criteria>

<output>
After completion, create `.planning/phases/13-smart-lead-creation/13-03-SUMMARY.md`
</output>
