---
phase: 18-agent-observatory
plan: 02
type: execute
wave: 2
depends_on: ["18-01", "18-03"]
files_modified:
  - bot/tracing/__init__.py
  - bot/agents/strategist.py
  - bot/agents/trainer.py
  - bot/agents/memory.py
  - bot/agents/extraction.py
  - bot/agents/reanalysis_strategist.py
  - bot/handlers/support.py
  - bot/handlers/learn.py
  - bot/handlers/train.py
  - bot/handlers/comment.py
  - bot/handlers/context_input.py
  - bot/main.py
autonomous: true

must_haves:
  truths:
    - "Every pipeline run (support, learn, train, re-analysis, comment) produces a Langfuse trace with hierarchical spans showing agent and LLM generation observations"
    - "Admin can see user_id, session_id, and pipeline name on every trace in the Langfuse dashboard"
    - "Bot starts and stops cleanly with Langfuse initialization and flush on shutdown"
    - "Comment handler LLM calls appear as Langfuse traces even though they bypass the pipeline system"
    - "All handlers pass model_config_service into PipelineContext so per-agent model overrides take effect"
    - "Re-analysis via /context command uses SimplePipelineCtx which calls agent.run() directly â€” per-agent model overrides do NOT apply there (acceptable limitation, documented in code comment)"
  artifacts:
    - path: "bot/tracing/__init__.py"
      provides: "Updated exports for Langfuse-based tracing"
      contains: "observe"
    - path: "bot/agents/strategist.py"
      provides: "Strategist agent with @observe decorator"
      contains: "@observe"
    - path: "bot/main.py"
      provides: "Langfuse init on startup, flush on shutdown"
      contains: "init_langfuse"
  key_links:
    - from: "bot/handlers/support.py"
      to: "langfuse"
      via: "@observe on pipeline wrapper function"
      pattern: "@observe"
    - from: "bot/agents/strategist.py"
      to: "langfuse"
      via: "@observe on agent.run()"
      pattern: "@observe"
    - from: "bot/main.py"
      to: "bot/tracing/langfuse_setup.py"
      via: "init_langfuse at startup, shutdown_langfuse at exit"
      pattern: "init_langfuse"
    - from: "bot/handlers/support.py"
      to: "bot/pipeline/context.py"
      via: "PipelineContext(model_config=model_config_service)"
      pattern: "model_config"
---

<objective>
Replace all custom tracing (@traced_span, TraceContext) across all agents and handlers with Langfuse @observe decorators, creating hierarchical traces for every pipeline run. Wire Langfuse initialization and shutdown into bot main.py. Also pass model_config_service into PipelineContext in all handlers so per-agent model overrides from Plan 03 take effect.

Purpose: This completes both the Langfuse integration AND the model config wiring -- after this plan, every AI interaction produces a full trace visible in the Langfuse dashboard, and per-agent model overrides are active in all pipeline runs.
Output: All 5 agents use @observe, all pipeline handlers use @observe for trace-level context, comment handler is instrumented, main.py manages Langfuse lifecycle, handlers pass model_config_service to PipelineContext.
</objective>

<execution_context>
@/Users/dmytrolevin/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dmytrolevin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/18-agent-observatory/18-RESEARCH.md
@.planning/phases/18-agent-observatory/18-01-SUMMARY.md
@.planning/phases/18-agent-observatory/18-03-SUMMARY.md
@bot/tracing/__init__.py
@bot/tracing/context.py
@bot/agents/strategist.py
@bot/agents/trainer.py
@bot/agents/memory.py
@bot/agents/extraction.py
@bot/agents/reanalysis_strategist.py
@bot/handlers/support.py
@bot/handlers/learn.py
@bot/handlers/train.py
@bot/handlers/comment.py
@bot/handlers/context_input.py
@bot/main.py
@bot/pipeline/context.py
@bot/services/model_config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Replace @traced_span with @observe on all agents and update tracing module</name>
  <files>bot/tracing/__init__.py, bot/agents/strategist.py, bot/agents/trainer.py, bot/agents/memory.py, bot/agents/extraction.py, bot/agents/reanalysis_strategist.py</files>
  <action>
1. **Update bot/tracing/__init__.py:**
   - Re-export `observe` from langfuse for convenience: `from langfuse import observe`
   - Keep re-exporting `init_collector` and `get_collector` for backward compatibility (the old TraceCollector still exists, we just stop using it)
   - Add re-export of `init_langfuse` and `shutdown_langfuse` from `bot.tracing.langfuse_setup`
   - Remove `traced_span` from `__all__` (deprecated)
   - The new `__all__` should be: `["observe", "init_langfuse", "shutdown_langfuse", "init_collector", "get_collector", "TraceContext", "get_current_trace_id"]`

2. **Update all 5 agents** (strategist.py, trainer.py, memory.py, extraction.py, reanalysis_strategist.py):
   For each agent:
   - Replace `from bot.tracing import traced_span` with `from langfuse import observe`
   - Replace `@traced_span("agent:{name}")` with `@observe(name="agent:{name}")` on the `run()` method
   - Keep everything else in the agent unchanged

   Specific replacements:
   - strategist.py: `@traced_span("agent:strategist")` -> `@observe(name="agent:strategist")`
   - trainer.py: `@traced_span("agent:trainer")` -> `@observe(name="agent:trainer")`
   - memory.py: `@traced_span("agent:memory")` -> `@observe(name="agent:memory")`
   - extraction.py: `@traced_span("agent:extraction")` -> `@observe(name="agent:extraction")`
   - reanalysis_strategist.py: `@traced_span("agent:reanalysis_strategist")` -> `@observe(name="agent:reanalysis_strategist")`

NOTE: Do NOT add `as_type="generation"` on agents. Agents are spans (not generations). Only LLM provider calls are generations. This creates the correct hierarchy: trace -> agent span -> LLM generation.
  </action>
  <verify>
    - `grep -r "traced_span" bot/agents/` returns nothing
    - `grep -c "@observe" bot/agents/strategist.py bot/agents/trainer.py bot/agents/memory.py bot/agents/extraction.py bot/agents/reanalysis_strategist.py` shows 1 per file
    - `python -c "from bot.agents.strategist import StrategistAgent; from bot.agents.trainer import TrainerAgent; print('OK')"` imports successfully
  </verify>
  <done>All 5 agents use @observe(name="agent:X") instead of @traced_span. tracing/__init__.py updated with Langfuse exports.</done>
</task>

<task type="auto">
  <name>Task 2: Replace TraceContext in handlers, pass model_config_service to PipelineContext, wire Langfuse lifecycle in main.py</name>
  <files>bot/handlers/support.py, bot/handlers/learn.py, bot/handlers/train.py, bot/handlers/comment.py, bot/handlers/context_input.py, bot/main.py</files>
  <action>
**Handler changes -- replace TraceContext with @observe wrapper functions AND pass model_config_service to PipelineContext:**

The pattern for each handler is the same. Currently:
```python
async with TraceContext(pipeline_name="support", telegram_id=tg_id, user_id=user.id or 0):
    async with ProgressUpdater(status_msg, Phase.ANALYSIS):
        await runner.run(pipeline_config, ctx)
```

Replace with an `@observe`-decorated helper function that sets trace-level metadata:

```python
from langfuse import observe, get_client

@observe(name="pipeline:support")
async def _traced_pipeline_run(runner, pipeline_config, ctx, tg_id, user_id):
    """Run pipeline with Langfuse trace context."""
    try:
        client = get_client()
        client.update_current_observation(
            user_id=str(tg_id),
            session_id=f"support_{tg_id}",
            metadata={"pipeline": "support", "user_id": user_id},
        )
    except Exception:
        pass  # Never break pipeline for observability
    return await runner.run(pipeline_config, ctx)
```

Then in the handler:
```python
async with ProgressUpdater(status_msg, Phase.ANALYSIS):
    await _traced_pipeline_run(runner, pipeline_config, ctx, tg_id, user.id or 0)
```

Apply this pattern to each handler, AND update every PipelineContext() construction to include `model_config=model_config_service`:

1. **bot/handlers/support.py** (2 TraceContext usages, 2 PipelineContext constructions):
   - Add `model_config_service` to the handler function parameters (it's available from dp.workflow_data)
   - Line ~173: add `model_config=model_config_service` to PipelineContext() constructor
   - Line ~187: main support pipeline -> create `_traced_support_run` with `@observe(name="pipeline:support")`
   - Line ~1002: add `model_config=model_config_service` to PipelineContext() constructor
   - Line ~1014: support regen -> create `_traced_support_regen_run` with `@observe(name="pipeline:support_regen")`
   - Remove `from bot.tracing import TraceContext` import
   - Add `from langfuse import observe, get_client` import
   - Add `from bot.services.model_config import ModelConfigService` if needed for type hints

2. **bot/handlers/learn.py** (1 TraceContext usage, 1 PipelineContext construction):
   - Add `model_config_service` to the handler function parameters
   - Line ~321: add `model_config=model_config_service` to PipelineContext() constructor
   - Line ~333: learn pipeline -> create `_traced_learn_run` with `@observe(name="pipeline:learn")`
   - Remove `from bot.tracing import TraceContext`
   - Add `from langfuse import observe, get_client`

3. **bot/handlers/train.py** (1 TraceContext usage, 1 PipelineContext construction):
   - Add `model_config_service` to the handler function parameters
   - Line ~290: add `model_config=model_config_service` to PipelineContext() constructor
   - Line ~302: train pipeline -> create `_traced_train_run` with `@observe(name="pipeline:train")`
   - Remove `from bot.tracing import TraceContext`
   - Add `from langfuse import observe, get_client`

4. **bot/handlers/comment.py** (0 TraceContext, 0 PipelineContext, but needs instrumentation):
   - The comment handler calls `llm.complete()` directly (lines ~115 and ~202), NOT through a pipeline
   - Create `_traced_comment_generate` with `@observe(name="pipeline:comment")` that wraps the llm.complete() call
   - This ensures comment generations appear in Langfuse too
   - Add `from langfuse import observe, get_client`
   - No PipelineContext changes needed (comment doesn't use pipelines)

5. **bot/handlers/context_input.py** (has SimplePipelineCtx, no TraceContext):
   - The re-analysis at line ~634 calls `agent.run()` directly via SimplePipelineCtx
   - Create `_traced_reanalysis_run` with `@observe(name="pipeline:reanalysis")` wrapping the agent.run() call
   - Add `from langfuse import observe, get_client`
   - NOTE: SimplePipelineCtx does NOT use the pipeline runner (it calls agent.run() directly), so per-agent model override here would require separate handling. For now, re-analysis uses the user's own provider. The model override system works for pipeline-based flows. This is acceptable since re-analysis is a power-user feature.

IMPORTANT: The @observe decorator automatically creates parent-child relationships. When `_traced_support_run` calls `runner.run()` which calls `agent.run()` (also @observe'd) which calls `llm.complete()` (also @observe'd), Langfuse creates: trace -> pipeline span -> agent span -> LLM generation. This happens automatically via Python's async context propagation.

IMPORTANT: Keep ProgressUpdater OUTSIDE the @observe wrapper. ProgressUpdater manages Telegram message editing and should not be nested inside the Langfuse trace function.

IMPORTANT for model_config_service: In aiogram, DI works by declaring the parameter name matching the key in dp.workflow_data. The key "model_config_service" was added to workflow_data in Plan 03's main.py changes. Handlers that need it just add `model_config_service: ModelConfigService` (or `model_config_service=None`) to their function signature. Use the flexible approach: `model_config_service=None` so handlers still work if the service isn't available.

**main.py changes:**

1. Add imports: `from bot.tracing.langfuse_setup import init_langfuse, shutdown_langfuse`
2. After `cfg = load_settings()` and `setup_logging()`, add:
   ```python
   langfuse_enabled = init_langfuse(cfg)
   if langfuse_enabled:
       logger.info("Langfuse observability enabled")
   ```
3. Keep the existing `trace_collector = init_collector(trace_repo)` and `await trace_collector.start()` for now (backward compat, will be removed in a future cleanup)
4. In the `finally` block, BEFORE `await insforge.close()`, add:
   ```python
   shutdown_langfuse()
   logger.info("Langfuse flushed")
   ```
  </action>
  <verify>
    - `grep -r "TraceContext" bot/handlers/` returns nothing (all replaced)
    - `grep -c "@observe" bot/handlers/support.py` returns 2 (main + regen)
    - `grep -c "@observe" bot/handlers/learn.py` returns 1
    - `grep -c "@observe" bot/handlers/train.py` returns 1
    - `grep -c "@observe" bot/handlers/comment.py` returns at least 1
    - `grep -c "@observe" bot/handlers/context_input.py` returns at least 1
    - `grep "init_langfuse" bot/main.py` shows initialization at startup
    - `grep "shutdown_langfuse" bot/main.py` shows flush at shutdown
    - `grep "model_config" bot/handlers/support.py` shows model_config_service being passed to PipelineContext
    - `grep "model_config" bot/handlers/learn.py` shows model_config_service being passed
    - `grep "model_config" bot/handlers/train.py` shows model_config_service being passed
    - `python -c "from bot.handlers.support import router; print('OK')"` succeeds
    - `python -c "from bot.main import main; print('OK')"` succeeds
  </verify>
  <done>All 5 pipeline entry points (support, support_regen, learn, train, comment) and re-analysis produce Langfuse traces with user_id and pipeline metadata. main.py initializes Langfuse on startup and flushes on shutdown. No TraceContext references remain in handler code. All pipeline handlers pass model_config_service to PipelineContext for per-agent model overrides.</done>
</task>

</tasks>

<verification>
- `grep -r "TraceContext" bot/handlers/` returns 0 results
- `grep -r "traced_span" bot/agents/ bot/services/` returns 0 results
- `grep -r "@observe" bot/agents/ bot/handlers/ bot/services/llm_router.py` shows decorators on all instrumented functions
- `grep -r "model_config" bot/handlers/support.py bot/handlers/learn.py bot/handlers/train.py` shows model_config_service in PipelineContext
- `python -c "from bot.main import main; print('All imports OK')"` succeeds without errors
- `grep "init_langfuse" bot/main.py` confirms startup wiring
</verification>

<success_criteria>
- All 5 agents decorated with @observe(name="agent:X")
- All 4 handler TraceContext usages replaced with @observe wrapper functions
- Comment handler LLM call wrapped with @observe
- Re-analysis agent call wrapped with @observe
- main.py initializes Langfuse on startup, flushes on shutdown
- Hierarchical trace structure: pipeline -> agent -> LLM generation (automatic via @observe nesting)
- All pipeline handlers pass model_config_service to PipelineContext
</success_criteria>

<output>
After completion, create `.planning/phases/18-agent-observatory/18-02-SUMMARY.md`
</output>
