---
phase: 11-performance-and-reliability
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - bot/storage/insforge_client.py
  - bot/main.py
  - bot/pipeline/runner.py
  - bot/handlers/support.py
autonomous: true

must_haves:
  truths:
    - "InsForge HTTP calls retry up to 3 times with exponential backoff on 429, 500, 502, 503 status codes"
    - "Non-retryable errors (400, 401, 403, 404, 409) propagate immediately without retry"
    - "All 4 asyncio.create_task() call sites have task references preventing garbage collection"
    - "Background task failures are logged at ERROR level via done callbacks"
    - "Knowledge base is loaded once at startup and reused (already implemented, verified)"
  artifacts:
    - path: "bot/storage/insforge_client.py"
      provides: "_request_with_retry method and retry integration in all HTTP methods"
      contains: "_request_with_retry"
    - path: "bot/main.py"
      provides: "Protected background tasks with task references and error callbacks"
      contains: "_background_tasks"
    - path: "bot/pipeline/runner.py"
      provides: "Protected background task in _run_background"
      contains: "_background_tasks"
    - path: "bot/handlers/support.py"
      provides: "Protected background task for lead enrichment"
      contains: "_background_tasks"
  key_links:
    - from: "bot/storage/insforge_client.py"
      to: "httpx.AsyncClient"
      via: "_request_with_retry wrapping all HTTP calls"
      pattern: "_request_with_retry"
    - from: "bot/main.py"
      to: "asyncio.create_task"
      via: "task reference set + done callback"
      pattern: "_background_tasks\\.add"
---

<objective>
Bot reliability hardening: add retry with exponential backoff to InsForge HTTP client, protect all background tasks from garbage collection and silent failures, and verify KB caching is already implemented.

Purpose: Prevent transient network failures from crashing pipelines and ensure fire-and-forget background tasks are properly managed.
Output: Resilient HTTP layer and safe background task management.
</objective>

<execution_context>
@/Users/dmytrolevin/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dmytrolevin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-performance-and-reliability/11-RESEARCH.md

@bot/storage/insforge_client.py
@bot/main.py
@bot/pipeline/runner.py
@bot/handlers/support.py
@bot/services/knowledge.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add retry with exponential backoff to InsForge HTTP client</name>
  <files>bot/storage/insforge_client.py</files>
  <action>
Add a private `_request_with_retry` method to the `InsForgeClient` class that wraps HTTP calls with exponential backoff.

1. Add module-level constants at the top of the file (after the `_POSTGREST_OPS` tuple):
   ```python
   RETRYABLE_STATUS_CODES = {429, 500, 502, 503}
   MAX_RETRIES = 3
   BASE_DELAY = 0.5  # seconds
   ```

2. Add `import asyncio` at the top imports.

3. Add the `_request_with_retry` method to InsForgeClient (after `_get_client`):
   ```python
   async def _request_with_retry(
       self,
       client: httpx.AsyncClient,
       method: str,
       *args: Any,
       **kwargs: Any,
   ) -> httpx.Response:
       """Execute HTTP request with exponential backoff on transient failures."""
       last_error: httpx.HTTPStatusError | None = None
       for attempt in range(MAX_RETRIES + 1):
           try:
               resp = await getattr(client, method)(*args, **kwargs)
               resp.raise_for_status()
               return resp
           except httpx.HTTPStatusError as e:
               if e.response.status_code not in RETRYABLE_STATUS_CODES:
                   raise
               last_error = e
               if attempt < MAX_RETRIES:
                   delay = BASE_DELAY * (2 ** attempt)
                   logger.warning(
                       "InsForge %s retryable error %d (attempt %d/%d), retrying in %.1fs",
                       method.upper(), e.response.status_code, attempt + 1, MAX_RETRIES + 1, delay,
                   )
                   await asyncio.sleep(delay)
       raise last_error  # type: ignore[misc]
   ```

4. Replace direct HTTP calls in all 6 methods that use the shared client. For each method, replace the pattern:
   ```python
   resp = await client.get(...)
   resp.raise_for_status()
   return resp.json()
   ```
   with:
   ```python
   resp = await self._request_with_retry(client, "get", ...)
   return resp.json()
   ```

   Specific changes:
   - `query()` (line 86-87): Replace `resp = await client.get(...)` + `resp.raise_for_status()` with `resp = await self._request_with_retry(client, "get", f"/{table}", params=params, headers=headers)`. Remove the `resp.raise_for_status()` line since retry handles it. Keep the `except httpx.HTTPStatusError` block for the 406/single case -- move the 406 check BEFORE the retry call by handling it in a separate try/except, OR restructure: the simplest approach is to keep `_request_with_retry` for status errors and handle 406 separately. Actually, the cleanest approach: in `query()`, call `_request_with_retry` but catch `HTTPStatusError` for the 406 case outside:
     ```python
     try:
         resp = await self._request_with_retry(client, "get", f"/{table}", params=params, headers=headers)
         return resp.json()
     except httpx.HTTPStatusError as e:
         if e.response.status_code == 406 and single:
             return None
         logger.error("InsForge query error on %s: %s", table, e)
         raise
     except Exception as e:
         logger.error("InsForge query error on %s: %s", table, e)
         raise
     ```
     Note: 406 is NOT in RETRYABLE_STATUS_CODES so `_request_with_retry` will re-raise it immediately, allowing the outer handler to catch it. This preserves existing behavior.

   - `create()` (line 104-112): Replace with `resp = await self._request_with_retry(client, "post", f"/{table}", json=[data], headers={...})`. Remove the `resp.raise_for_status()` line. Keep existing error handling.

   - `update()` (line 139-147): Replace with `resp = await self._request_with_retry(client, "patch", f"/{table}", params=params, json=data, headers={...})`. Remove `resp.raise_for_status()`.

   - `upsert()` (line 169-173): Replace with `resp = await self._request_with_retry(client, "post", f"/{table}", json=[data], headers=headers)`. Remove `resp.raise_for_status()`.

   - `delete()` (line 196): Replace with `await self._request_with_retry(client, "delete", f"/{table}", params=params)`. Remove `resp.raise_for_status()`.

5. Do NOT add retry to `upload_file()` or `rpc()` -- these use separate one-shot `httpx.AsyncClient` instances. `upload_file` handles large binary uploads that shouldn't auto-retry. `rpc` is rarely used and its one-shot client pattern would need restructuring.
  </action>
  <verify>
1. Run `python3 -c "from bot.storage.insforge_client import InsForgeClient; print('Import OK')"` -- should succeed.
2. Grep: `grep -c '_request_with_retry' bot/storage/insforge_client.py` -- should return 6 (1 definition + 5 call sites in query/create/update/upsert/delete).
3. Grep: `grep 'RETRYABLE_STATUS_CODES' bot/storage/insforge_client.py` -- should show {429, 500, 502, 503}.
  </verify>
  <done>
- _request_with_retry method exists with exponential backoff (0.5s, 1s, 2s delays)
- 5 HTTP methods (query, create, update, upsert, delete) route through retry
- upload_file and rpc remain unchanged (separate client instances)
- Non-retryable errors (400, 401, 403, 404, 406, 409) propagate immediately
- Retryable errors (429, 500, 502, 503) retry up to 3 times with backoff
  </done>
</task>

<task type="auto">
  <name>Task 2: Protect background tasks with references and error callbacks</name>
  <files>bot/main.py, bot/pipeline/runner.py, bot/handlers/support.py</files>
  <action>
There are 4 unprotected `asyncio.create_task()` calls across 3 files. Each needs a task reference (preventing GC) and an error callback (preventing silent failures).

**Pattern to apply everywhere:**

Create a shared helper. Since these 3 files are in different packages, the cleanest approach is a small utility. Add a new utility function in `bot/utils.py` (which does NOT exist yet -- but `bot/utils.py` already exists for formatting helpers). Actually, check: `bot/utils.py` is the Telegram formatting helpers file. Better to add a `_create_background_task` helper as a module-level function in each file, OR create a tiny `bot/task_utils.py`. Since there are 3 call sites across 3 files, create `bot/task_utils.py`:

```python
"""Background task management -- prevents GC and logs errors."""

from __future__ import annotations

import asyncio
import logging

logger = logging.getLogger(__name__)

_background_tasks: set[asyncio.Task] = set()  # type: ignore[type-arg]


def create_background_task(coro, *, name: str | None = None) -> asyncio.Task:  # type: ignore[type-arg]
    """Create a background task with reference tracking and error logging.

    Prevents garbage collection of fire-and-forget tasks and ensures
    exceptions are logged at ERROR level instead of being silently swallowed.
    """
    task = asyncio.create_task(coro, name=name)
    _background_tasks.add(task)

    def _on_done(t: asyncio.Task) -> None:  # type: ignore[type-arg]
        _background_tasks.discard(t)
        if t.cancelled():
            logger.debug("Background task %s was cancelled", t.get_name())
        elif exc := t.exception():
            logger.error(
                "Background task %s failed: %s", t.get_name(), exc, exc_info=exc,
            )

    task.add_done_callback(_on_done)
    return task
```

Then update each call site:

**bot/main.py** (2 call sites):

1. Add import: `from bot.task_utils import create_background_task`

2. Line 180-182 (followup scheduler): Replace:
   ```python
   asyncio.create_task(
       start_followup_scheduler(bot, lead_repo, activity_repo)
   )
   ```
   with:
   ```python
   create_background_task(
       start_followup_scheduler(bot, lead_repo, activity_repo),
       name="followup_scheduler",
   )
   ```

3. Line 196 (scenario generation loop): Replace:
   ```python
   asyncio.create_task(_scenario_generation_loop())
   ```
   with:
   ```python
   create_background_task(
       _scenario_generation_loop(),
       name="scenario_generation_loop",
   )
   ```

**bot/pipeline/runner.py** (1 call site):

1. Add import: `from bot.task_utils import create_background_task`

2. Line 106 in `_run_background`: Replace:
   ```python
   asyncio.create_task(_bg_task())
   ```
   with:
   ```python
   create_background_task(_bg_task(), name=f"bg_agent_{step.agent}")
   ```

**bot/handlers/support.py** (1 call site):

1. Add import: `from bot.task_utils import create_background_task`

2. Line 320 (lead enrichment): Replace:
   ```python
   asyncio.create_task(
       _background_enrich_lead(...)
   )
   ```
   with:
   ```python
   create_background_task(
       _background_enrich_lead(
           lead_id=saved_lead_id,
           lead_repo=lead_repo,
           engagement_service=engagement_service,
           openrouter_api_key=shared_openrouter_key,
           prospect_name=prospect_name,
           prospect_company=prospect_company,
           prospect_geography=prospect_geography,
           original_context=user_input[:300],
       ),
       name=f"enrich_lead_{saved_lead_id}",
   )
   ```

**PERF-V11-02 verification (KB caching -- already done):**
No code changes needed. Verify by reading `bot/services/knowledge.py` and `bot/main.py`:
- `KnowledgeService.__init__` sets `_playbook = ""` and `_company_knowledge = ""`
- `knowledge.load()` is called once at line 84 of main.py
- The `knowledge` instance is passed via `dp.workflow_data` to all handlers
- No other code path calls `knowledge.load()` or re-reads from disk
Log this verification in the summary.
  </action>
  <verify>
1. Run `python3 -c "from bot.task_utils import create_background_task; print('Import OK')"` -- should succeed.
2. Run `python3 -c "from bot.main import main; print('Import OK')"` -- should succeed (validates all imports).
3. Grep: `grep -rn 'asyncio.create_task' bot/main.py bot/pipeline/runner.py bot/handlers/support.py` -- should return ZERO matches (all replaced with create_background_task).
4. Grep: `grep -rn 'create_background_task' bot/main.py bot/pipeline/runner.py bot/handlers/support.py` -- should return 4 matches total (2 in main.py, 1 in runner.py, 1 in support.py).
5. Verify KB caching: `grep 'knowledge.load' bot/main.py` shows exactly 1 call. `grep -rn 'knowledge.load\|playbook_path.read_text\|company_path.read_text' bot/` shows reads only in knowledge.py (the cached loader).
  </verify>
  <done>
- bot/task_utils.py exists with create_background_task helper
- All 4 bare asyncio.create_task() calls replaced with create_background_task()
- Each background task has a descriptive name for log identification
- Task references stored in module-level set (prevents GC)
- Error callback logs failures at ERROR level with exc_info
- PERF-V11-02 verified: KB loaded once at startup, no re-reads
  </done>
</task>

</tasks>

<verification>
1. Import check: `python3 -c "from bot.storage.insforge_client import InsForgeClient; from bot.task_utils import create_background_task; from bot.main import main; print('All imports OK')"`
2. No bare create_task remaining: `grep -rn 'asyncio\.create_task' bot/main.py bot/pipeline/runner.py bot/handlers/support.py` returns nothing
3. Retry constants present: `grep 'RETRYABLE_STATUS_CODES\|MAX_RETRIES\|BASE_DELAY' bot/storage/insforge_client.py`
4. Background tasks protected: `grep -rn 'create_background_task' bot/main.py bot/pipeline/runner.py bot/handlers/support.py` returns 4 matches
5. KB caching confirmed: `grep -c 'knowledge.load' bot/main.py` returns 1
</verification>

<success_criteria>
- PERF-V11-02: KB caching verified as already implemented (no code changes, documented)
- PERF-V11-03: InsForge client retries 429/500/502/503 up to 3 times with exponential backoff
- PERF-V11-04: All 4 background tasks have references and error callbacks
- All Python imports resolve cleanly
- No bare asyncio.create_task() calls remain in main.py, runner.py, support.py
</success_criteria>

<output>
After completion, create `.planning/phases/11-performance-and-reliability/11-02-SUMMARY.md`
</output>
