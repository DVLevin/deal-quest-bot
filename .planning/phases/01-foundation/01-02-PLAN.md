---
phase: 01-foundation
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - bot/main.py
  - bot/handlers/learn.py
  - bot/handlers/train.py
  - bot/handlers/support.py
autonomous: true

must_haves:
  truths:
    - "Every pipeline execution in learn, train, and support handlers creates a trace record"
    - "TraceCollector is initialized at bot startup and stopped at shutdown"
    - "trace_repo is available via DI (workflow_data) for Phase 2 admin commands"
    - "Existing ProgressUpdater behavior is unchanged — TraceContext wraps outside it"
    - "Pipeline failures still propagate to users — TraceContext does not suppress exceptions"
  artifacts:
    - path: "bot/main.py"
      provides: "DI wiring for TraceRepo, TraceCollector init/stop lifecycle"
      contains: "trace_repo"
    - path: "bot/handlers/learn.py"
      provides: "TraceContext wrapping learn pipeline call site"
      contains: "TraceContext"
    - path: "bot/handlers/train.py"
      provides: "TraceContext wrapping train pipeline call site"
      contains: "TraceContext"
    - path: "bot/handlers/support.py"
      provides: "TraceContext wrapping support pipeline call sites"
      contains: "TraceContext"
  key_links:
    - from: "bot/main.py"
      to: "bot/tracing/collector.py"
      via: "init_collector(trace_repo) at startup, collector.stop() at shutdown"
      pattern: "init_collector"
    - from: "bot/handlers/learn.py"
      to: "bot/tracing/context.py"
      via: "async with TraceContext wrapping ProgressUpdater + runner.run"
      pattern: "TraceContext"
    - from: "bot/handlers/train.py"
      to: "bot/tracing/context.py"
      via: "async with TraceContext wrapping ProgressUpdater + runner.run"
      pattern: "TraceContext"
    - from: "bot/handlers/support.py"
      to: "bot/tracing/context.py"
      via: "async with TraceContext wrapping ProgressUpdater + runner.run"
      pattern: "TraceContext"
---

<objective>
Wire tracing into the bot lifecycle and instrument all pipeline handler call sites.

Purpose: Connect the tracing module (built in Plan 01) to the running bot so every pipeline execution generates a trace. This is the final step before traces flow end-to-end from handler to InsForge.

Output: Updated main.py with TraceCollector lifecycle, updated learn/train/support handlers with TraceContext wrapping at each `runner.run()` call site.
</objective>

<execution_context>
@/Users/dmytrolevin/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dmytrolevin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-01-SUMMARY.md

@bot/main.py — DI wiring, startup/shutdown lifecycle
@bot/handlers/learn.py — Learn pipeline call sites (ProgressUpdater + runner.run)
@bot/handlers/train.py — Train pipeline call sites (ProgressUpdater + runner.run)
@bot/handlers/support.py — Support pipeline call sites (ProgressUpdater + runner.run)
@bot/services/progress.py — ProgressUpdater pattern (TraceContext wraps OUTSIDE this)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire TraceCollector lifecycle and TraceRepo DI into main.py</name>
  <files>bot/main.py</files>
  <action>
Modify `bot/main.py` to initialize and manage the tracing system:

1. **Add imports** at the top (after existing storage imports):
```python
from bot.tracing import init_collector
from bot.tracing.collector import get_collector
from bot.storage.repositories import TraceRepo  # add to existing import
```

2. **Initialize TraceRepo** after other repo initialization (after `generated_scenario_repo = ...` around line 74):
```python
trace_repo = TraceRepo(insforge)
```

3. **Initialize and start TraceCollector** after repo initialization but before DI wiring (before `dp.workflow_data.update`):
```python
# Initialize tracing collector
trace_collector = init_collector(trace_repo)
await trace_collector.start()
logger.info("Trace collector started")
```

4. **Add trace_repo to workflow_data** (inside the dp.workflow_data.update dict):
```python
"trace_repo": trace_repo,
```

5. **Stop collector at shutdown** — in the `finally` block (before `await insforge.close()`):
```python
collector = get_collector()
if collector:
    await collector.stop()
    logger.info("Trace collector stopped")
```

Important: The TraceCollector.start() is async (creates a background task), so it must be called inside the async main() function. The stop() ensures buffered traces are flushed before the InsForge client is closed.
  </action>
  <verify>
    - `python -c "import ast; ast.parse(open('bot/main.py').read()); print('Syntax OK')"` succeeds
    - grep confirms `trace_repo` and `init_collector` appear in main.py
    - grep confirms `collector.stop()` appears in the finally block
  </verify>
  <done>
    - TraceRepo initialized alongside other repositories
    - TraceCollector started during bot startup, stopped during shutdown
    - trace_repo available via workflow_data for handler injection
    - Shutdown flushes remaining trace buffer before closing InsForge client
  </done>
</task>

<task type="auto">
  <name>Task 2: Instrument learn, train, and support handlers with TraceContext</name>
  <files>
    bot/handlers/learn.py
    bot/handlers/train.py
    bot/handlers/support.py
  </files>
  <action>
Add TraceContext wrapping at every `runner.run()` call site in the three handler files. The pattern is: wrap the existing `ProgressUpdater` block (or the `runner.run()` call) with `TraceContext` as the OUTER context manager.

**Pattern to apply at each call site:**

Before:
```python
async with ProgressUpdater(status_msg, Phase.EVALUATION):
    await runner.run(pipeline_config, ctx)
```

After:
```python
async with TraceContext(pipeline_name="learn", telegram_id=tg_id, user_id=user.id):
    async with ProgressUpdater(status_msg, Phase.EVALUATION):
        await runner.run(pipeline_config, ctx)
```

**bot/handlers/learn.py** — Add `from bot.tracing import TraceContext` to imports. Wrap these call sites:
- Line ~328-329: The main learn evaluation pipeline. Use `pipeline_name="learn"`. Get `telegram_id` from the message/callback (look for `tg_id` or `message.from_user.id` variable in the surrounding handler function). Get `user_id` from `user.id` (the UserModel loaded earlier in the handler).
- Line ~245: Transcription ProgressUpdater. This is NOT a pipeline call (it's AssemblyAI transcription), so do NOT wrap it with TraceContext.

**bot/handlers/train.py** — Add `from bot.tracing import TraceContext` to imports. Wrap these call sites:
- Line ~297-298: The main train evaluation pipeline. Use `pipeline_name="train"`. Get telegram_id and user_id from surrounding context variables.
- Line ~415: Transcription ProgressUpdater — do NOT wrap (same as learn).

**bot/handlers/support.py** — Add `from bot.tracing import TraceContext` to imports. Wrap these call sites:
- Line ~154-155: Support text analysis pipeline. Use `pipeline_name="support"`.
- Line ~845-846: Support regeneration pipeline (callback handler). Use `pipeline_name="support_regen"`.
- Line ~621: Transcription ProgressUpdater — do NOT wrap.

**Finding telegram_id and user_id at each call site:**
- In each handler, look for how `user` (UserModel) is obtained. Typically: `user = await user_repo.get_by_telegram_id(message.from_user.id)` or similar.
- `telegram_id` = `message.from_user.id` or the equivalent variable already in scope (often stored as `tg_id`)
- `user_id` = `user.id` (from the UserModel). If user.id could be None, default to 0.

**Critical rules:**
- TraceContext goes OUTSIDE ProgressUpdater (trace wraps the whole pipeline execution including progress updates)
- Do NOT modify anything inside the ProgressUpdater block
- Do NOT modify PipelineRunner or pipeline configs
- If TraceContext raises during __aexit__ (e.g., collector error), it should not affect the user — the collector.record_trace call in context.py should be wrapped in try/except
- The handler's existing error handling (try/except around the pipeline block) should remain unchanged
  </action>
  <verify>
    - `python -c "import ast; ast.parse(open('bot/handlers/learn.py').read()); print('learn.py OK')"` succeeds
    - `python -c "import ast; ast.parse(open('bot/handlers/train.py').read()); print('train.py OK')"` succeeds
    - `python -c "import ast; ast.parse(open('bot/handlers/support.py').read()); print('support.py OK')"` succeeds
    - grep confirms TraceContext appears in all three handler files
    - grep confirms TraceContext does NOT appear near transcription sections (only near runner.run calls)
  </verify>
  <done>
    - learn.py has TraceContext wrapping the learn pipeline runner.run() call
    - train.py has TraceContext wrapping the train pipeline runner.run() call
    - support.py has TraceContext wrapping both the support and support_regen pipeline runner.run() calls
    - Transcription blocks are NOT wrapped (they're not pipeline calls)
    - ProgressUpdater behavior is completely unchanged
    - Exception handling is unchanged — TraceContext doesn't suppress errors
  </done>
</task>

</tasks>

<verification>
Syntax check all modified files:
```bash
cd deal-quest-bot
python -c "
import ast
for f in ['bot/main.py', 'bot/handlers/learn.py', 'bot/handlers/train.py', 'bot/handlers/support.py']:
    ast.parse(open(f).read())
    print(f'{f}: OK')
print('All files parse successfully')
"
```

Verify imports resolve:
```bash
python -c "
from bot.tracing import TraceContext, init_collector, get_collector
from bot.storage.repositories import TraceRepo
print('All tracing imports OK')
"
```

Verify TraceContext appears at runner.run call sites:
```bash
grep -n "TraceContext" bot/handlers/learn.py bot/handlers/train.py bot/handlers/support.py
```
Expected: TraceContext import + usage near each runner.run() call site (learn: 1 site, train: 1 site, support: 2 sites).
</verification>

<success_criteria>
- Bot startup initializes TraceCollector with TraceRepo
- Bot shutdown flushes remaining traces and stops collector
- Every pipeline runner.run() call in learn, train, and support handlers is wrapped with TraceContext
- TraceContext is the outer wrapper (outside ProgressUpdater)
- Transcription blocks are not instrumented (not pipeline calls)
- No changes to PipelineRunner internals
- All files parse without syntax errors
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-02-SUMMARY.md`
</output>
